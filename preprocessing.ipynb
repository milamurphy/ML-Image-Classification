{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f239d8f7",
   "metadata": {},
   "source": [
    "Extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47421a47-2a86-41cf-884a-85f4c42fd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x cifar-10-batches-py/\n",
      "x cifar-10-batches-py/data_batch_4\n",
      "x cifar-10-batches-py/readme.html\n",
      "x cifar-10-batches-py/test_batch\n",
      "x cifar-10-batches-py/data_batch_3\n",
      "x cifar-10-batches-py/batches.meta\n",
      "x cifar-10-batches-py/data_batch_2\n",
      "x cifar-10-batches-py/data_batch_5\n",
      "x cifar-10-batches-py/data_batch_1\n",
      "x cifar-100-python/\n",
      "x cifar-100-python/file.txt~\n",
      "x cifar-100-python/train\n",
      "x cifar-100-python/test\n",
      "x cifar-100-python/meta\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-100-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e202b22",
   "metadata": {},
   "source": [
    "Load CIFAR10 (And print classes to find the ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ef199a4-0acc-4878-b3c5-c03ec8c64397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10 classes:\n",
      "0 airplane\n",
      "1 automobile\n",
      "2 bird\n",
      "3 cat\n",
      "4 deer\n",
      "5 dog\n",
      "6 frog\n",
      "7 horse\n",
      "8 ship\n",
      "9 truck\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f, encoding='bytes')\n",
    "\n",
    "# CIFAR-10\n",
    "meta10 = unpickle(\"cifar-10-batches-py/batches.meta\")\n",
    "cifar10_classes = [x.decode('utf-8') for x in meta10[b'label_names']]\n",
    "\n",
    "print(\"CIFAR-10 classes:\")\n",
    "for i, name in enumerate(cifar10_classes):\n",
    "    print(i, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c591133",
   "metadata": {},
   "source": [
    "Load CIFAR10 (And print classes to find the ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae44c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CIFAR-100 fine labels (100 classes):\n",
      "0 apple\n",
      "1 aquarium_fish\n",
      "2 baby\n",
      "3 bear\n",
      "4 beaver\n",
      "5 bed\n",
      "6 bee\n",
      "7 beetle\n",
      "8 bicycle\n",
      "9 bottle\n",
      "10 bowl\n",
      "11 boy\n",
      "12 bridge\n",
      "13 bus\n",
      "14 butterfly\n",
      "15 camel\n",
      "16 can\n",
      "17 castle\n",
      "18 caterpillar\n",
      "19 cattle\n",
      "20 chair\n",
      "21 chimpanzee\n",
      "22 clock\n",
      "23 cloud\n",
      "24 cockroach\n",
      "25 couch\n",
      "26 crab\n",
      "27 crocodile\n",
      "28 cup\n",
      "29 dinosaur\n",
      "30 dolphin\n",
      "31 elephant\n",
      "32 flatfish\n",
      "33 forest\n",
      "34 fox\n",
      "35 girl\n",
      "36 hamster\n",
      "37 house\n",
      "38 kangaroo\n",
      "39 keyboard\n",
      "40 lamp\n",
      "41 lawn_mower\n",
      "42 leopard\n",
      "43 lion\n",
      "44 lizard\n",
      "45 lobster\n",
      "46 man\n",
      "47 maple_tree\n",
      "48 motorcycle\n",
      "49 mountain\n",
      "50 mouse\n",
      "51 mushroom\n",
      "52 oak_tree\n",
      "53 orange\n",
      "54 orchid\n",
      "55 otter\n",
      "56 palm_tree\n",
      "57 pear\n",
      "58 pickup_truck\n",
      "59 pine_tree\n",
      "60 plain\n",
      "61 plate\n",
      "62 poppy\n",
      "63 porcupine\n",
      "64 possum\n",
      "65 rabbit\n",
      "66 raccoon\n",
      "67 ray\n",
      "68 road\n",
      "69 rocket\n",
      "70 rose\n",
      "71 sea\n",
      "72 seal\n",
      "73 shark\n",
      "74 shrew\n",
      "75 skunk\n",
      "76 skyscraper\n",
      "77 snail\n",
      "78 snake\n",
      "79 spider\n",
      "80 squirrel\n",
      "81 streetcar\n",
      "82 sunflower\n",
      "83 sweet_pepper\n",
      "84 table\n",
      "85 tank\n",
      "86 telephone\n",
      "87 television\n",
      "88 tiger\n",
      "89 tractor\n",
      "90 train\n",
      "91 trout\n",
      "92 tulip\n",
      "93 turtle\n",
      "94 wardrobe\n",
      "95 whale\n",
      "96 willow_tree\n",
      "97 wolf\n",
      "98 woman\n",
      "99 worm\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-100\n",
    "meta100 = unpickle(\"cifar-100-python/meta\")\n",
    "cifar100_fine_classes = [x.decode('utf-8') for x in meta100[b'fine_label_names']]\n",
    "cifar100_coarse_classes = [x.decode('utf-8') for x in meta100[b'coarse_label_names']]\n",
    "\n",
    "print(\"\\nCIFAR-100 fine labels (100 classes):\")\n",
    "for i, name in enumerate(cifar100_fine_classes):\n",
    "    print(i, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8999e018",
   "metadata": {},
   "source": [
    "Extract the ids we need for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "363250c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 3072) (35000,)\n",
      "(7000, 3072) (7000,)\n"
     ]
    }
   ],
   "source": [
    "cifar10_needed_ids = [1, 2, 3, 4, 5, 7, 9] # automobile, bird, cat, deer, dog, horse, truck\n",
    "\n",
    "X_train_10 = []\n",
    "y_train_10 = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    batch = unpickle(f\"cifar-10-batches-py/data_batch_{i}\")\n",
    "    X_train_10.append(batch[b'data'])\n",
    "    y_train_10.append(batch[b'labels'])\n",
    "\n",
    "X_train_10 = np.concatenate(X_train_10)\n",
    "y_train_10 = np.concatenate(y_train_10)\n",
    "\n",
    "# filter only needed CIFAR-10 classes\n",
    "train_mask_10 = np.isin(y_train_10, cifar10_needed_ids)\n",
    "X_train_10_filtered = X_train_10[train_mask_10]\n",
    "y_train_10_filtered = y_train_10[train_mask_10]\n",
    "\n",
    "# filter CIFAR-10 test batch\n",
    "test_batch = unpickle(\"cifar-10-batches-py/test_batch\")\n",
    "X_test_10 = test_batch[b'data']\n",
    "y_test_10 = np.array(test_batch[b'labels'])\n",
    "\n",
    "test_mask_10 = np.isin(y_test_10, cifar10_needed_ids)\n",
    "X_test_10_filtered = X_test_10[test_mask_10]\n",
    "y_test_10_filtered = y_test_10[test_mask_10]\n",
    "\n",
    "print(X_train_10_filtered.shape, y_train_10_filtered.shape)\n",
    "print(X_test_10_filtered.shape, y_test_10_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954388a6",
   "metadata": {},
   "source": [
    "The shape of these matrices make sense as <br>\n",
    "X_train_10 filtered 50,000 training images and we only took 7 classes out of 10 so that is 35,000, and it has 32px x 32px x 3(RGB) = 3072. y_train_10 filtered is also 35000 <br>\n",
    "X_test_filtered has 7000 rows which makes sense as we originally had 10000 but took only 7 classes out of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1dbd99",
   "metadata": {},
   "source": [
    "Extract the ids we need for CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81b10e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8500, 3072) (8500,)\n",
      "(1700, 3072) (1700,)\n"
     ]
    }
   ],
   "source": [
    "cifar100_needed_ids = [4, 6, 7, 9, 11, 12, 13, 18, 20, 21, 33, 34, 35, 38, 46, 49, 54]\n",
    "\n",
    "train_100 = unpickle(\"cifar-100-python/train\")\n",
    "X_train_100 = train_100[b'data']\n",
    "y_train_100 = np.array(train_100[b'fine_labels'])\n",
    "\n",
    "test_100 = unpickle(\"cifar-100-python/test\")\n",
    "X_test_100 = test_100[b'data']\n",
    "y_test_100 = np.array(test_100[b'fine_labels'])\n",
    "\n",
    "# Filter only needed classes\n",
    "train_mask_100 = np.isin(y_train_100, cifar100_needed_ids)\n",
    "X_train_100_filtered = X_train_100[train_mask_100]\n",
    "y_train_100_filtered = y_train_100[train_mask_100]\n",
    "\n",
    "test_mask_100 = np.isin(y_test_100, cifar100_needed_ids)\n",
    "X_test_100_filtered = X_test_100[test_mask_100]\n",
    "y_test_100_filtered = y_test_100[test_mask_100]\n",
    "\n",
    "print(X_train_100_filtered.shape, y_train_100_filtered.shape)\n",
    "print(X_test_100_filtered.shape, y_test_100_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143e0f8",
   "metadata": {},
   "source": [
    "Same here for CIFAR-100, we had 50,000 images but took 17 classes so 8500 images <br>\n",
    "The test data had 10,000 but we took 17 so now 1700"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad3d8b",
   "metadata": {},
   "source": [
    "Combine CIFAR-10 and CIFAR-100 and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c3a7d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43500, 3072) (43500,)\n",
      "(8700, 3072) (8700,)\n"
     ]
    }
   ],
   "source": [
    "X_train_combined = np.concatenate([X_train_10_filtered, X_train_100_filtered])\n",
    "y_train_combined = np.concatenate([y_train_10_filtered, y_train_100_filtered])\n",
    "\n",
    "X_test_combined = np.concatenate([X_test_10_filtered, X_test_100_filtered])\n",
    "y_test_combined = np.concatenate([y_test_10_filtered, y_test_100_filtered])\n",
    "\n",
    "print(X_train_combined.shape, y_train_combined.shape)\n",
    "print(X_test_combined.shape, y_test_combined.shape)\n",
    "\n",
    "os.makedirs('combined', exist_ok=True)\n",
    "\n",
    "train_data = {'features': X_train_combined, 'labels': y_train_combined}\n",
    "test_data  = {'features': X_test_combined, 'labels': y_test_combined}\n",
    "\n",
    "# 0.1 for 10% of training split\n",
    "val_split = int(0.1 * X_train_combined.shape[0])\n",
    "val_data = {'features': X_train_combined[:val_split], 'labels': y_train_combined[:val_split]}\n",
    "train_data = {'features': X_train_combined[val_split:], 'labels': y_train_combined[val_split:]}\n",
    "\n",
    "with open('combined/train.p', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "with open('combined/valid.p', 'wb') as f:\n",
    "    pickle.dump(val_data, f)\n",
    "with open('combined/test.p', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f3572",
   "metadata": {},
   "source": [
    "Now we are reading in the train_data, val_data and test_data that we just created and checking the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44b9449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39150, 3072) (4350, 3072) (8700, 3072)\n",
      "(39150,) (4350,) (8700,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('combined/train.p', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('combined/valid.p', 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open('combined/test.p', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train_data['features'], train_data['labels']\n",
    "X_val, y_val = val_data['features'], val_data['labels']\n",
    "X_test, y_test = test_data['features'], test_data['labels']\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b41ff",
   "metadata": {},
   "source": [
    "We need to reshape it to the correct size to be able to apply pre-processing to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5744a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39150, 32, 32, 3) (4350, 32, 32, 3) (8700, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 32, 32, 3)\n",
    "X_val   = X_val.reshape(-1, 32, 32, 3)\n",
    "X_test  = X_test.reshape(-1, 32, 32, 3)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8660420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f07157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca83fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
